{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13ac1ad",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\annem\\anaconda3\\lib\\site-packages (1.25.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Error parsing requirements for tensorflow-estimator: [Errno 2] No such file or directory: 'c:\\\\users\\\\annem\\\\anaconda3\\\\lib\\\\site-packages\\\\tensorflow_estimator-2.10.0.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for keras: [Errno 2] No such file or directory: 'c:\\\\users\\\\annem\\\\anaconda3\\\\lib\\\\site-packages\\\\keras-2.10.0.dist-info\\\\METADATA'\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\annem\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\annem\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\annem\\anaconda3\\lib\\site-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\annem\\anaconda3\\lib\\site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\annem\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Error parsing requirements for tensorflow-estimator: [Errno 2] No such file or directory: 'c:\\\\users\\\\annem\\\\anaconda3\\\\lib\\\\site-packages\\\\tensorflow_estimator-2.10.0.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for keras: [Errno 2] No such file or directory: 'c:\\\\users\\\\annem\\\\anaconda3\\\\lib\\\\site-packages\\\\keras-2.10.0.dist-info\\\\METADATA'\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\annem\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries, by using \"!\" it will connect to terminal\n",
    "!pip install numpy\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c8406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8672dda",
   "metadata": {},
   "source": [
    "Implement a class for n-sided polygons and a class for points in a Euclidean system, namely polygon and point respectively. For example, a 4-sided polygon can be defined by 4 points P1, P2, P3, P4, and P1-P4 are each points of the form point(X,Y), and X and Y are coordinates on the X and Y axis, respectively. The edges are listed counterclockwise starting at the lower left: P1 to P2, P2 to P3, P3 to P4, and P4 to P1. The polygon class should work for polygons of any number of edges and have a function perimeter that returns its perimeter (sum of the lengths of the edges). (20points)\n",
    "\n",
    "Hint: use the Pythagorian theorem: if a line segment Z starts at (X1,Y1) and ends at (X2, Y2), the length of Z is the square root of (X1-X2)^2 + (Y1-Y2)^2.\n",
    "\n",
    "Example: The perimeter of the polygon/triangle on point(1,1), point(1,2), and point(2,2) is 3.4; The perimeter of the 4-sided polygon on point(2,1), point(2,3), point(6,3), and point(4,1) is 10.8; print out these two examples. (10points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d185ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class Point\n",
    "import math\n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        #print(self.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5182ce9",
   "metadata": {},
   "source": [
    "# to calculate perimeter we need to define the length between edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39e95378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#points should have x and y coordinates\n",
    "class Polygon:\n",
    "   # def __init__(self, point):\n",
    "    def __init__(self, *points):\n",
    "        self.points = points\n",
    "        #print(points)\n",
    "    def perimeter(self):\n",
    "        if len(self.points) < 2:\n",
    "            return 0\n",
    "        perimeter = 0\n",
    "        num_points = len(self.points)\n",
    "        for i in range(num_points):\n",
    "            p1 = self.points[i]\n",
    "            p2 = self.points[(i + 1) % num_points]\n",
    "            length = self.calculate_edge_length(p1, p2)\n",
    "            perimeter += length\n",
    "\n",
    "        return perimeter\n",
    "\n",
    "#     def perimeter(self):\n",
    "#         if len(self.points) < 2:\n",
    "#             return 0\n",
    "#         perimeter = 0\n",
    "#         for i in range(len(self.points)):\n",
    "#             p1 = self.points[i]\n",
    "#             #print(p1)\n",
    "#             #This line assigns the next point in the list of self.points to the variable p2.\n",
    "#             #The % operator is used to ensure that when i reaches the last point in the list, \n",
    "#             #print(len(self.points))\n",
    "        \n",
    "#             p2 = self.points[(i + 1) % len(self.points)] \n",
    "#            # print(p2)# Wrap around to the first point for the last edge\n",
    "#             length = self.calculate_edge_length(p1, p2)\n",
    "#             perimeter += length\n",
    "\n",
    "       # return perimeter\n",
    "    #below function calculatesthe distancebetween edges\n",
    "    def calculate_edge_length(self, p1, p2):\n",
    "        dx = p1.x - p2.x\n",
    "        dy = p1.y - p2.y\n",
    "        #use the Pythagorian the length of Z is the square root of (X1-X2)^2 + (Y1-Y2)^2.\n",
    "        length = math.sqrt(dx**2 + dy**2)\n",
    "        return length\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e653b809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The perimeter of the triangle is: 3.4\n",
      "The perimeter of the quadrilateral is: 10.8\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "triangle = Polygon(Point(1, 1), Point(1, 2), Point(2, 2))\n",
    "quad = Polygon(Point(2, 1), Point(2, 3), Point(6, 3), Point(4, 1))\n",
    "#circle = Polygon(Point(1, 1), Point(2, 2), Point(3, 3), Point(4, 4), Point(5,5))\n",
    "# Calculate and print the perimeters\n",
    "print(\"The perimeter of the triangle is:\", round(triangle.perimeter(), 1))\n",
    "print(\"The perimeter of the quadrilateral is:\", round(quad.perimeter(), 1))\n",
    "#print(round(circle.perimeter()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36349dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f20a0689",
   "metadata": {},
   "source": [
    "Use Pandas to load both data/AIS/transit_segments.csv, and data/AIS/vessel_information.csv. Show the first 5 rows of each dataset to inspect it.(10points)\n",
    "For data/AIS/vessel_information.csv, keep only those rows with the type value occurring for at least 100 times in the dataset. (10points)\n",
    "Merge data/AIS/vessel_information.csv and data/AIS/transit_segments.csv on the \"mmsi\" column using outer join. (10points)\n",
    "If you are not allowed to call the inner join provided by Pandas but have the above outer join results, how to get the results of inner join? You can use other functions provided by Pandas (but not a function that directly implements the inner join). (10points)\n",
    "Now directly call the inner join provided by Pandas, check whether your results above are exactly the same.(10points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535302e6",
   "metadata": {},
   "source": [
    "# Below code to load csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b100e7a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transit Segments Dataset:\n",
      "   mmsi               name  transit  segment  seg_length  avg_sog  min_sog  \\\n",
      "0     1        Us Govt Ves        1        1         5.1     13.2      9.2   \n",
      "1     1  Dredge Capt Frank        1        1        13.5     18.6     10.4   \n",
      "2     1      Us Gov Vessel        1        1         4.3     16.2     10.3   \n",
      "3     1      Us Gov Vessel        2        1         9.2     15.4     14.5   \n",
      "4     1  Dredge Capt Frank        2        1         9.2     15.4     14.6   \n",
      "\n",
      "   max_sog  pdgt10        st_time       end_time  \n",
      "0     14.5    96.5  2/10/09 16:03  2/10/09 16:27  \n",
      "1     20.6   100.0   4/6/09 14:31   4/6/09 15:20  \n",
      "2     20.5   100.0   4/6/09 14:36   4/6/09 14:55  \n",
      "3     16.1   100.0  4/10/09 17:58  4/10/09 18:34  \n",
      "4     16.2   100.0  4/10/09 17:59  4/10/09 18:35  \n",
      "\n",
      "Vessel Information Dataset:\n",
      "   mmsi  num_names                                              names sov  \\\n",
      "0     1          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y   \n",
      "1     9          3                         000000009/Raven/Shearwater   N   \n",
      "2    21          1                                      Us Gov Vessel   Y   \n",
      "3    74          2                                  Mcfaul/Sarah Bell   N   \n",
      "4   103          3           Ron G/Us Navy Warship 103/Us Warship 103   Y   \n",
      "\n",
      "      flag flag_type  num_loas                                    loa  \\\n",
      "0  Unknown   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0   \n",
      "1  Unknown   Unknown         2                              50.0/62.0   \n",
      "2  Unknown   Unknown         1                                  208.0   \n",
      "3  Unknown   Unknown         1                                  155.0   \n",
      "4  Unknown   Unknown         2                             26.0/155.0   \n",
      "\n",
      "   max_loa  num_types                             type  \n",
      "0    156.0          4  Dredging/MilOps/Reserved/Towing  \n",
      "1     62.0          2                     Pleasure/Tug  \n",
      "2    208.0          1                          Unknown  \n",
      "3    155.0          1                          Unknown  \n",
      "4    155.0          2                   Tanker/Unknown  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load transit_segments.csv\n",
    "ts = pd.read_csv('transit_segments.csv')\n",
    "\n",
    "# Load vessel_information.csv\n",
    "vi = pd.read_csv('vessel_information.csv')\n",
    "\n",
    "# Display the first 5 rows of each dataset\n",
    "print(\"Transit Segments Dataset:\")\n",
    "print(ts.head(5))\n",
    "\n",
    "print(\"\\nVessel Information Dataset:\")\n",
    "print(vi.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41ffe02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "value = vi.isnull().values.any()\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50ec2774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mmsi', 'num_names', 'names', 'sov', 'flag', 'flag_type', 'num_loas',\n",
      "       'loa', 'max_loa', 'num_types', 'type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#print(vi.count(type))\n",
    "#print(vi(type))\n",
    "print(vi.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18fb8608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['type', 'num_types', 'max_loa', 'loa', 'num_loas', 'flag_type', 'flag',\n",
      "       'sov', 'names', 'num_names', 'mmsi'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(vi.columns[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c90f0a",
   "metadata": {},
   "source": [
    "## For data/AIS/vessel_information.csv, keep only those rows with the type value occurring for at least 100 times in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10ff677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter vessel_information to keep rows with 'type' value occurring at least 100 times\n",
    "type_counts = vi['type'].value_counts()\n",
    "common_types = type_counts[type_counts >= 100].index\n",
    "#print(common_types)\n",
    "#for i in common_types:\n",
    "   # fi=vi[vi[common_types]]\n",
    "f_v_i = vi[vi['type'].isin(common_types)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86c36e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262526\n"
     ]
    }
   ],
   "source": [
    "print(len(ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7b4666",
   "metadata": {},
   "source": [
    "# Using Outer Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6bc57cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262526\n"
     ]
    }
   ],
   "source": [
    "# Merge the datasets using outer join on the \"mmsi\" column\n",
    "merged_data_outer = pd.merge(vi, ts, on=\"mmsi\", how=\"outer\")\n",
    "merged_data_outer\n",
    "print(len(merged_data_outer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08ea01b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b95113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the common column used for the join (in this case, \"mmsi\")\n",
    "#common_column = \"mmsi\"\n",
    "\n",
    "# Filter rows where the common column is not null in both dataframes\n",
    "#inner_join_results2= merged_data_outer[merged_data_outer[common_column].notnull()]\n",
    "#outer will give the results for all the values present in both datframes..\n",
    "#by removing the NAN values we can achieve only inner values\n",
    "#mi=merged_data_outer(drop(NaN))\n",
    "#mi=merged_data_outer.dropna('NaN')\n",
    "#by using left outer then remove nan values\n",
    "inner_join_results = pd.merge(vi, ts, on=\"mmsi\", how=\"left\")\n",
    "\n",
    "# Drop rows with NaN values (rows that didn't have a match in the other dataframe)\n",
    "inner_join_results.dropna(inplace=True)\n",
    "\n",
    "#mi=merged_data_outer.dropna()\n",
    "#mi\n",
    "# Filter the rows where there are no NaN values (equivalent to an inner join)\n",
    "inner_join_result = merged_data_outer.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9488ead",
   "metadata": {},
   "source": [
    "# to get the inner join without outer just we can use\n",
    "# remove the null valuez from the outer join \n",
    "# beacuse outer join is were it contains all the merged values, were inner join is related to the first frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8a40a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_join_result = merged_data_outer.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01c22f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "297cceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using inner function \n",
    "merged_data_inner = pd.merge(vi, ts, on=\"mmsi\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3cd0d41",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mmsi</th>\n",
       "      <th>num_names</th>\n",
       "      <th>names</th>\n",
       "      <th>sov</th>\n",
       "      <th>flag</th>\n",
       "      <th>flag_type</th>\n",
       "      <th>num_loas</th>\n",
       "      <th>loa</th>\n",
       "      <th>max_loa</th>\n",
       "      <th>num_types</th>\n",
       "      <th>...</th>\n",
       "      <th>name</th>\n",
       "      <th>transit</th>\n",
       "      <th>segment</th>\n",
       "      <th>seg_length</th>\n",
       "      <th>avg_sog</th>\n",
       "      <th>min_sog</th>\n",
       "      <th>max_sog</th>\n",
       "      <th>pdgt10</th>\n",
       "      <th>st_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...</td>\n",
       "      <td>Y</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>7</td>\n",
       "      <td>42.0/48.0/57.0/90.0/138.0/154.0/156.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Us Govt Ves</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>13.2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>14.5</td>\n",
       "      <td>96.5</td>\n",
       "      <td>2/10/09 16:03</td>\n",
       "      <td>2/10/09 16:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...</td>\n",
       "      <td>Y</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>7</td>\n",
       "      <td>42.0/48.0/57.0/90.0/138.0/154.0/156.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Dredge Capt Frank</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.5</td>\n",
       "      <td>18.6</td>\n",
       "      <td>10.4</td>\n",
       "      <td>20.6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4/6/09 14:31</td>\n",
       "      <td>4/6/09 15:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...</td>\n",
       "      <td>Y</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>7</td>\n",
       "      <td>42.0/48.0/57.0/90.0/138.0/154.0/156.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Us Gov Vessel</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>16.2</td>\n",
       "      <td>10.3</td>\n",
       "      <td>20.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4/6/09 14:36</td>\n",
       "      <td>4/6/09 14:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...</td>\n",
       "      <td>Y</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>7</td>\n",
       "      <td>42.0/48.0/57.0/90.0/138.0/154.0/156.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Us Gov Vessel</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9.2</td>\n",
       "      <td>15.4</td>\n",
       "      <td>14.5</td>\n",
       "      <td>16.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4/10/09 17:58</td>\n",
       "      <td>4/10/09 18:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...</td>\n",
       "      <td>Y</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>7</td>\n",
       "      <td>42.0/48.0/57.0/90.0/138.0/154.0/156.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>Dredge Capt Frank</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9.2</td>\n",
       "      <td>15.4</td>\n",
       "      <td>14.6</td>\n",
       "      <td>16.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4/10/09 17:59</td>\n",
       "      <td>4/10/09 18:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262348</th>\n",
       "      <td>999999999</td>\n",
       "      <td>1</td>\n",
       "      <td>Triple Attraction</td>\n",
       "      <td>N</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Triple Attraction</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>20.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6/15/10 12:49</td>\n",
       "      <td>6/15/10 13:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262349</th>\n",
       "      <td>999999999</td>\n",
       "      <td>1</td>\n",
       "      <td>Triple Attraction</td>\n",
       "      <td>N</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Triple Attraction</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.2</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6/15/10 21:32</td>\n",
       "      <td>6/15/10 22:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262350</th>\n",
       "      <td>999999999</td>\n",
       "      <td>1</td>\n",
       "      <td>Triple Attraction</td>\n",
       "      <td>N</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Triple Attraction</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>17.4</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>18.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6/17/10 19:16</td>\n",
       "      <td>6/17/10 20:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262351</th>\n",
       "      <td>999999999</td>\n",
       "      <td>1</td>\n",
       "      <td>Triple Attraction</td>\n",
       "      <td>N</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Triple Attraction</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>31.5</td>\n",
       "      <td>14.2</td>\n",
       "      <td>13.4</td>\n",
       "      <td>15.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6/18/10 2:52</td>\n",
       "      <td>6/18/10 5:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262352</th>\n",
       "      <td>999999999</td>\n",
       "      <td>1</td>\n",
       "      <td>Triple Attraction</td>\n",
       "      <td>N</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Triple Attraction</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>18.6</td>\n",
       "      <td>16.1</td>\n",
       "      <td>19.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6/18/10 10:19</td>\n",
       "      <td>6/18/10 11:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262353 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             mmsi  num_names  \\\n",
       "0               1          8   \n",
       "1               1          8   \n",
       "2               1          8   \n",
       "3               1          8   \n",
       "4               1          8   \n",
       "...           ...        ...   \n",
       "262348  999999999          1   \n",
       "262349  999999999          1   \n",
       "262350  999999999          1   \n",
       "262351  999999999          1   \n",
       "262352  999999999          1   \n",
       "\n",
       "                                                    names sov     flag  \\\n",
       "0       Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y  Unknown   \n",
       "1       Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y  Unknown   \n",
       "2       Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y  Unknown   \n",
       "3       Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y  Unknown   \n",
       "4       Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y  Unknown   \n",
       "...                                                   ...  ..      ...   \n",
       "262348                                  Triple Attraction   N  Unknown   \n",
       "262349                                  Triple Attraction   N  Unknown   \n",
       "262350                                  Triple Attraction   N  Unknown   \n",
       "262351                                  Triple Attraction   N  Unknown   \n",
       "262352                                  Triple Attraction   N  Unknown   \n",
       "\n",
       "       flag_type  num_loas                                    loa  max_loa  \\\n",
       "0        Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0    156.0   \n",
       "1        Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0    156.0   \n",
       "2        Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0    156.0   \n",
       "3        Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0    156.0   \n",
       "4        Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0    156.0   \n",
       "...          ...       ...                                    ...      ...   \n",
       "262348   Unknown         1                                   30.0     30.0   \n",
       "262349   Unknown         1                                   30.0     30.0   \n",
       "262350   Unknown         1                                   30.0     30.0   \n",
       "262351   Unknown         1                                   30.0     30.0   \n",
       "262352   Unknown         1                                   30.0     30.0   \n",
       "\n",
       "        num_types  ...               name transit  segment  seg_length  \\\n",
       "0               4  ...        Us Govt Ves       1        1         5.1   \n",
       "1               4  ...  Dredge Capt Frank       1        1        13.5   \n",
       "2               4  ...      Us Gov Vessel       1        1         4.3   \n",
       "3               4  ...      Us Gov Vessel       2        1         9.2   \n",
       "4               4  ...  Dredge Capt Frank       2        1         9.2   \n",
       "...           ...  ...                ...     ...      ...         ...   \n",
       "262348          1  ...  Triple Attraction       3        1         5.3   \n",
       "262349          1  ...  Triple Attraction       4        1        18.7   \n",
       "262350          1  ...  Triple Attraction       6        1        17.4   \n",
       "262351          1  ...  Triple Attraction       7        1        31.5   \n",
       "262352          1  ...  Triple Attraction       8        1        19.8   \n",
       "\n",
       "        avg_sog  min_sog  max_sog  pdgt10        st_time       end_time  \n",
       "0          13.2      9.2     14.5    96.5  2/10/09 16:03  2/10/09 16:27  \n",
       "1          18.6     10.4     20.6   100.0   4/6/09 14:31   4/6/09 15:20  \n",
       "2          16.2     10.3     20.5   100.0   4/6/09 14:36   4/6/09 14:55  \n",
       "3          15.4     14.5     16.1   100.0  4/10/09 17:58  4/10/09 18:34  \n",
       "4          15.4     14.6     16.2   100.0  4/10/09 17:59  4/10/09 18:35  \n",
       "...         ...      ...      ...     ...            ...            ...  \n",
       "262348     20.0     19.6     20.4   100.0  6/15/10 12:49  6/15/10 13:05  \n",
       "262349     19.2     18.4     19.9   100.0  6/15/10 21:32  6/15/10 22:29  \n",
       "262350     17.0     14.7     18.4   100.0  6/17/10 19:16  6/17/10 20:17  \n",
       "262351     14.2     13.4     15.1   100.0   6/18/10 2:52   6/18/10 5:03  \n",
       "262352     18.6     16.1     19.5   100.0  6/18/10 10:19  6/18/10 11:22  \n",
       "\n",
       "[262353 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "561c3a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare two dataframes\n",
    "#print(df1.equals(df2))\n",
    "#print(mi.equals(merged_data_inner))inner_join_results\n",
    "#print(merged_data_inner.equals(inner_join_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cac27a6",
   "metadata": {},
   "source": [
    "# comparition between innerjoin results using inner join and without usin inner join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c2ac2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Reset the index for both DataFrames\n",
    "merged_data_inner = merged_data_inner.reset_index(drop=True)\n",
    "inner_join_result = inner_join_result.reset_index(drop=True)\n",
    "\n",
    "# make the columns are in the same order\n",
    "merged_data_inner = merged_data_inner[inner_join_result.columns]\n",
    "\n",
    "comparison_result = merged_data_inner.compare(inner_join_result)\n",
    "\n",
    "are_identical = comparison_result.empty\n",
    "\n",
    "# Print the result\n",
    "print(are_identical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d62f1501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "comparison_result = merged_data_inner.compare(inner_join_result)\n",
    "print(comparison_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11d6bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ea4162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa19ef3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd8d35d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb2797d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
